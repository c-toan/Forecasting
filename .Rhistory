library(neuralnet)
install.packages("mlbench")
library(mlbench)
data(BreastCancer)
df <- BreastCancer
#manipulate dataset
df$label <- ifelse(df$Class=='benign', 0, 1)
#get rid of class so no info leakage
df <- df %>% select(-Class)
df <- df %>% select(-Id)
df <- na.omit(df)
#EDA and class disribution
table(Actual=df$label) #very close to class imbalance
summary(df)
dim(df)
#changing factors to int
df$Cl.thickness <- as.integer(df$Cl.thickness)
df$Cell.size<- as.integer(df$Cell.size)
df$Cell.shape<- as.integer(df$Cell.shape)
df$Marg.adhesion<- as.integer(df$Marg.adhesion)
df$Epith.c.size<- as.integer(df$Epith.c.size)
df$Bare.nuclei<- as.integer(df$Bare.nuclei)
df$Bl.cromatin<- as.integer(df$Bl.cromatin)
df$Normal.nucleoli<- as.integer(df$Normal.nucleoli)
df$Mitoses<- as.integer(df$Mitoses)
df$label <- as.factor(df$label)
#data splitting
set.seed(123)
set.split <- sample.split(df$label, 0.7)
test_set.brst <- subset(df, set.split=="FALSE")
train_set.brst <- subset(df, set.split=="TRUE")
#first model
model_1 <- glm(label~.,data = train_set.brst, family = binomial)
prob.brst_train<- predict(model_1, type = "response")
#performances on training set
pred_classes_train <- ifelse(prob.brst_train>0.5,1,0)
conf_matrix_train <- table(Predicted=pred_classes_train, Actual=train_set.brst$label )
print(conf_matrix_train)
#performance on test set
prob.brst_test<- predict(model_1, newdata = test_set.brst, type = "response")
pred_classes_test<- ifelse(prob.brst_test>0.5,1,0)
conf_matrix_test <- table(Predicted=pred_classes_test, Actual=test_set.brst$label )
print(conf_matrix_test)
#looking at ROC curve
roc(test_set.brst$label, as.numeric(prob.brst_test))
plot(roc(test_set.brst$label, as.numeric(prob.brst_test)), col="blue")
#metrics training set
accuracy.train <- sum(diag(conf_matrix_train)) / sum(conf_matrix_train)
sensitivity.train <- conf_matrix_train[2, 2] / sum(conf_matrix_train[2, ])
specificity.train <- conf_matrix_train[1, 1] / sum(conf_matrix_train[1, ])
precision.train <- conf_matrix_train[2, 2] / sum(conf_matrix_train[, 2])
f1_score.train <- 2 * (precision.train * sensitivity.train) / (precision.train + sensitivity.train)
cat("Accuracy training set:", accuracy.train, "\n")
cat("Sensitivity training set (Recall):", sensitivity.train, "\n")
cat("Specificity training set:", specificity.train, "\n")
cat("Precision training set:", precision.train, "\n")
cat("F1 Score training:", f1_score.train, "\n")
#metrics on test set
accuracy_test <- sum(diag(conf_matrix_test)) / sum(conf_matrix_test)
sensitivity_test <- conf_matrix_test[2, 2] / sum(conf_matrix_test[2, ])
specificity_test <- conf_matrix_test[1, 1] / sum(conf_matrix_test[1, ])
precision_test <- conf_matrix_test[2, 2] / sum(conf_matrix_test[, 2])
f1_score_test <- 2 * (precision_test * sensitivity_test) / (precision_test + sensitivity_test)
cat("Accuracy test set:", accuracy_test, "\n")
cat("Sensitivity test set (Recall):", sensitivity_test, "\n")
cat("Specificity test set:", specificity_test, "\n")
cat("Precision test set:", precision_test, "\n")
cat("F1 Score test set:", f1_score_test, "\n")
# Prepare data
importance_mod1 <- varImp(model_1, scale=TRUE)
importance_df <- as.data.frame(importance_mod1)
importance_df$Variable <- rownames(importance_df)
# Plot
library(ggplot2)
ggplot(importance_df, aes(x = reorder(Variable, Overall), y = Overall)) +
geom_point(size = 4, color = "dodgerblue3") +
coord_flip() +
labs(
title = "Variable Importance plot imbalanced Logistic Regression",
x = "Features",
y = "Importance (Overall)"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 12),
axis.title = element_text(size = 10),
axis.text = element_text(size = 8))
#fixing class imbalance
set.seed(123)
# Downsample the training set
train_set.down <- downSample(x = train_set.brst %>% select(-label),
y = train_set.brst$label,
yname = "label")
# Check the new class distribution
table(train_set.down$label)
#new model perfs on test set
model_bal <- glm(label~.,data = train_set.down, family = binomial)
prob.brst_bal<- predict(model_bal, newdata = test_set.brst, type = "response")
#performances on test set balanced to ensure as few false negative
pred_classes_bal <- ifelse(prob.brst_bal>0.5,1,0)
conf_matrix_bal <- table(Predicted=pred_classes_bal, Actual=test_set.brst$label )
print(conf_matrix_bal)
#metrics on test set balanced
accuracy_bal <- sum(diag(conf_matrix_bal)) / sum(conf_matrix_bal)
sensitivity_bal <- conf_matrix_bal[2, 2] / sum(conf_matrix_bal[2, ])
specificity_bal <- conf_matrix_bal[1, 1] / sum(conf_matrix_bal[1, ])
precision_bal <- conf_matrix_bal[2, 2] / sum(conf_matrix_bal[, 2])
f1_score_bal <- 2 * (precision_bal * sensitivity_bal) / (precision_bal + sensitivity_bal)
cat("Accuracy:", accuracy_bal, "\n")
cat("Sensitivity (Recall):", sensitivity_bal, "\n")
cat("Specificity:", specificity_bal, "\n")
cat("Precision:", precision_bal, "\n")
cat("F1 Score:", f1_score_bal, "\n")
#variable importance
importance_modbal <- varImp(model_bal, scale = TRUE)
importance_df_bal <- as.data.frame(importance_modbal)
importance_df_bal$Variable <- rownames(importance_df)
# Plot
ggplot(importance_df_bal, aes(x = reorder(Variable, Overall), y = Overall)) +
geom_point(size = 4, color = "dodgerblue3") +
coord_flip() +
labs(
title = "Variable Importance plot balanced logistic regression",
x = "Features",
y = "Importance (Overall)"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 12),
axis.title = element_text(size = 10),
axis.text = element_text(size = 8)
)
#PDP analysis GLM balanced
#bare nuclei
pdp_bare <- partial(model_bal, pred.var = "Bare.nuclei", plot = TRUE)
print(pdp_bare)
#normal nuclei
pdp_nuclei <- partial(model_bal, pred.var = "Normal.nucleoli", plot=TRUE)
print(pdp_nuclei)
#Marginal adhesion
pdp_marg <- partial(model_bal, pred.var = "Marg.adhesion", plot=TRUE)
print(pdp_marg)
#Cell.size
pdp_size <- partial(model_bal, pred.var = "Cell.size", plot=TRUE)
print(pdp_size)
#mitoses
pdp_mit <- partial(model_bal, pred.var = "Mitoses", plot=TRUE)
print(pdp_mit)
rf_model_train <- randomForest(label ~ ., data = train_set.brst, importance = TRUE)
pred_rf_train <- predict(rf_model_train)
confusionMatrix(pred_rf_train, train_set.brst$label)
#random forest test set
rf_model_test <- randomForest(label ~ ., data = train_set.brst, importance = TRUE)
pred_rf_test <- predict(rf_model_test, newdata=test_set.brst)
confusionMatrix(pred_rf_test, test_set.brst$label)
#var importance of rf model imbalanced
importance_rf <- as.data.frame(importance(rf_model_test))
importance_rf$Variable <- rownames(importance_rf)
# Plot
ggplot(importance_rf, aes(x = reorder(Variable, MeanDecreaseGini), y = MeanDecreaseGini)) +
geom_point(size = 4, color = "dodgerblue3") +
coord_flip() +
labs(
title = "Variable Importance plot imbalanced Random Forest",
x = "Features",
y = "Mean decrease in Gini"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 12),
axis.title = element_text(size = 10),
axis.text = element_text(size = 8)
)
#random forest with balanced dataset
rf_model_bal <- randomForest(label ~ ., data = train_set.down, importance = TRUE)
pred_rf_bal <- predict(rf_model_bal, newdata=test_set.brst)
install.packages("caTools")
install.packages("caret")
#we see that false negatives have decreased (very good!!)
install.packages("randomForest")
install.packages("pdp")
install.packages("nnet")
install.packages(c("neuralnet", "keras", "tensorflow"), dependencies = T)
install.packages("mlbench")
install.packages("caretEnsemble")
confusionMatrix(pred_rf_bal, test_set.brst$label)
#var importance of rf model balanced
importance_rf_bal <- as.data.frame(importance(rf_model_bal))
importance_rf_bal$Variable <- rownames(importance_rf_bal)
# Plot
ggplot(importance_rf_bal, aes(x = reorder(Variable, MeanDecreaseGini), y = MeanDecreaseGini)) +
geom_point(size = 4, color = "dodgerblue3") +
coord_flip() +
labs(
title = "Variable Importance plot balanced Random Forest",
x = "Features",
y = "Mean decrease in Gini"
) +
theme_minimal() +
theme(
plot.title = element_text(size = 12),
axis.title = element_text(size = 10),
axis.text = element_text(size = 8)
)
pdprf_size <- partial(rf_model_bal, pred.var = "Cell.size", plot=TRUE)
print(pdprf_size)
pdprf_bare <- partial(rf_model_bal, pred.var="Bare.nuclei", plot=TRUE)
print(pdprf_bare)
pdprf_shape <- partial(rf_model_bal, pred.var = "Cell.shape", plot=TRUE)
print(pdprf_shape)
#trying the neural network with balanced class
set.seed(223)
nn_model <- nnet(label ~ ., data = train_set.down, size = 10 ,maxit = 500, decay = 0.005)
pred_probs_nn <- predict(nn_model, test_set.brst, type = "raw")
pred_classes_nn <- ifelse(pred_probs_nn > 0.5, 1, 0)
# Confusion matrix
conf_matrix_nn <- table(Predicted = pred_classes_nn, Actual = test_set.brst$label)
print(conf_matrix_nn)
# Evaluate
accuracy_nn <- sum(diag(conf_matrix_nn)) / sum(conf_matrix_nn)
precision_nn <- conf_matrix_nn[2, 2] / sum(conf_matrix_nn[, 2])
recall_nn <- conf_matrix_nn[2, 2] / sum(conf_matrix_nn[2, ])
f1_nn <- 2 * (precision_nn * recall_nn) / (precision_nn + recall_nn)
cat("\nAccuracy:", accuracy_nn)
cat("\nPrecision:", precision_nn)
cat("\nRecall (Sensitivity):", recall_nn)
cat("\nF1 Score:", f1_nn, "\n")
y_train <- ifelse(train_set.down$label == 1, 1, 0)
y_test <- ifelse(test_set.brst$label == 1, 1, 0)
# Normalisation (tu l'avais déjà fait, on reprend)
normalize <- function(x) {
return((x - min(x)) / (max(x) - min(x)))
}
x_train <- as.data.frame(lapply(train_set.down[, -which(names(train_set.down) == "label")], normalize))
x_test <- as.data.frame(lapply(test_set.brst[, -which(names(test_set.brst) == "label")], normalize))
# keras example or nnet
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("randomForest")
install.packages("nnet")
install.packages(c("neuralnet", "keras", "tensorflow"), dependencies = T)
install.packages("mlbench")
install.packages("caretEnsemble")
install.packages("pdp")
install.packages("mlbench")
install.packages("pdp")
install.packages("caretEnsemble")
install.packages(c("neuralnet", "keras", "tensorflow"), dependencies = T)
install.packages(c("neuralnet", "keras", "tensorflow"), dependencies = T)
install.packages("caretEnsemble")
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages(keras)
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("keras")
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("keras")
pdp_bare <- partial(model_bal, pred.var = "Bare.nuclei", plot = TRUE)
+theme_minimal()
#PDP analysis GLM balanced
#bare nuclei
pdp_bare <- partial(model_bal, pred.var = "Bare.nuclei", plot = TRUE)
print(pdp_bare)
#normal nuclei
pdp_nuclei <- partial(model_bal, pred.var = "Normal.nucleoli", plot=TRUE)
print(pdp_nuclei)
#Marginal adhesion
pdp_marg <- partial(model_bal, pred.var = "Marg.adhesion", plot=TRUE)
print(pdp_marg)
#Cell.size
pdp_size <- partial(model_bal, pred.var = "Cell.size", plot=TRUE)
print(pdp_size)
#mitoses
pdp_mit <- partial(model_bal, pred.var = "Mitoses", plot=TRUE)
print(pdp_mit)
install.packages("keras")
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("keras")
install.packages("keras")
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("keras")
install.packages("keras")
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
install.packages("keras")
install_keras()
library(keras)
install_keras()
model_nn <- keras_model_sequential() %>%
layer_dense(units = 100, activation = "relu", input_shape = c(ncol(x_train))) %>%
layer_dense(units = 1, activation = "sigmoid")
#PDP analysis GLM balanced
#bare nuclei
pdp_bare <- partial(model_bal, pred.var = "Bare.nuclei", plot = TRUE)
print(pdp_bare)
#normal nuclei
pdp_nuclei <- partial(model_bal, pred.var = "Normal.nucleoli", plot=TRUE)
print(pdp_nuclei)
#Marginal adhesion
pdp_marg <- partial(model_bal, pred.var = "Marg.adhesion", plot=TRUE)
print(pdp_marg)
#Cell.size
pdp_size <- partial(model_bal, pred.var = "Cell.size", plot=TRUE)
print(pdp_size)
#mitoses
pdp_mit <- partial(model_bal, pred.var = "Mitoses", plot=TRUE)
print(pdp_mit)
#cell shape
pdp_mit <- partial(model_bal, pred.var ="Cell.shape", plot=TRUE)
print(pdp_mit)
conf_mat(df, truth = df$label, estimate = .pred_class_test)
library(yardstick)
install.packages("yardstick")
library(yardstick)
autoplot(conf_mat(df, truth = df$label, estimate = .pred_class_test))
library(yardstick)
autoplot(conf_mat(df, truth = label, estimate = .pred_class_test))
colnames(df)
df <- data.frame(
label = true_labels,
.pred_1 = pred_probs
)
colnames(df)
pdprf_size <- partial(rf_model_bal, pred.var = "Cell.size", plot=TRUE)
print(pdprf_size)
pdprf_bare <- partial(rf_model_bal, pred.var="Bare.nuclei", plot=TRUE)
print(pdprf_bare)
pdprf_shape <- partial(rf_model_bal, pred.var = "Cell.shape", plot=TRUE)
print(pdprf_shape)
pdprf_shape <- partial(rf_model_bal, pred.var = "Mitoses", plot=TRUE)
print(pdprf_shape)
# PCA Analysis
pca_data <- df %>% select(-label)  # Remove target variable
# Perform PCA
pca_result <- prcomp(pca_data, scale. = TRUE)
# Summary of PCA
summary(pca_result)
# Create data frame for plotting
pca_df <- data.frame(pca_result$x[, 1:2], Label = df$label)
# Plot PCA results
ggplot(pca_df, aes(x = PC1, y = PC2, color = Label)) +
geom_point(alpha = 0.7) +
labs(title = "PCA of Breast Cancer Dataset",
x = paste0("PC1 (", round(100 * pca_result$sdev[1]^2/sum(pca_result$sdev^2), 1), "%)"),
y = paste0("PC2 (", round(100 * pca_result$sdev[2]^2/sum(pca_result$sdev^2), 1), "%)")) +
theme_minimal()
# Scree plot to determine important components
screeplot(pca_result, type = "lines", main = "Scree Plot")
#loadings of the pca
loadings_pca <- pca_result$rotation
print(loadings_pca)
# Barplot for PC1 loadings
barplot(loadings_pca[, 1], main = "PC1 Loadings", las = 2, col = "skyblue", ylab = "Contribution")+ theme_minimal()
# Barplot for PC2 loadings
barplot(loadings_pca[, 2], main = "PC2 Loadings", las = 2, col = "lightgreen", ylab = "Contribution") + theme_minimal()
barplot(loadings_pca[, 2], main = "PC2 Loadings", las = 2, col = "lightgreen", ylab = "Contribution", xlab = element_text(size =8)) + theme_minimal()
#loadings of the pca
loadings_pca <- pca_result$rotation
print(loadings_pca)
# Barplot for PC1 loadings
barplot(loadings_pca[, 1], main = "PC1 Loadings", las = 2, col = "skyblue", ylab = "Contribution")+ theme_minimal()
# Barplot for PC2 loadings
barplot(loadings_pca[, 2], main = "PC2 Loadings", las = 2, col = "lightgreen", ylab = "Contribution") + theme_minimal()
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tsibble)
library(lubridate)
library(fable)
library(feasts)
library(readr)
library(zoo)
library(tidyr)
# Load and preprocess the traffic data
df_traffic <- read_csv("traffic_data.csv")[-1, ]  # Remove header row
df_traffic <- df_traffic %>%
mutate(
datetime = dmy_hm(Time),
traffic = as.numeric(Sensor198)
) %>%
select(datetime, traffic) %>%
as_tsibble(index = datetime)
df_traffic %>% autoplot(traffic) +
labs(title = "Traffic at Sensor 198", x = "Time", y = "Traffic")
ggplot(df_traffic, aes(x = traffic)) +
geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black") +
labs(title = "Distribution of Traffic Values", x = "Traffic", y = "Count")
gg_season(df_traffic, traffic, period = "month") +
labs(title = "Monthly Seasonality", x = "Date", y = "Traffic")
gg_season(df_traffic, traffic, period = "week") +
labs(title = "Weekly Seasonality", x = "Date", y = "Traffic")
df_traffic %>%
mutate(weekday = factor(weekdays(datetime), levels = c("Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday", "Sunday")),
hour = hour(datetime)) %>%
group_by(weekday, hour) %>%
summarise(mean_traffic = mean(traffic, na.rm = TRUE)) %>%
ggplot(aes(x = hour, y = mean_traffic)) +
geom_line() +
facet_wrap(~ weekday, ncol = 3) +
labs(title = "Average Hourly Traffic by Day", x = "Hour", y = "Traffic")
df_traffic %>% ACF(traffic) %>% autoplot() +
labs(title = "Autocorrelation Function")
# Add holiday flag
df_traffic <- df_traffic %>%
mutate(date = as_date(datetime))
holidays <- as_date(c(
"2015-01-01", "2015-01-19", "2015-02-16", "2015-03-31", "2015-05-25",
"2015-07-04", "2015-09-07", "2015-10-12", "2015-11-11", "2015-11-26",
"2015-11-27", "2015-12-25", "2016-01-01", "2016-01-18", "2016-02-15",
"2016-03-31", "2016-05-30", "2016-07-04", "2016-09-05", "2016-10-10",
"2016-11-11", "2016-11-24", "2016-11-25", "2016-12-25"
))
df_traffic <- df_traffic %>% mutate(holiday = as.integer(date %in% holidays))
df_traffic %>%
group_by(holiday) %>%
summarise(mean_traffic = mean(traffic, na.rm = TRUE)) %>%
mutate(holiday = factor(holiday, labels = c("Non-Holiday", "Holiday"))) %>%
ggplot(aes(x = holiday, y = mean_traffic)) +
geom_col(fill = "lightblue") +
labs(title = "Mean Traffic by Holiday Status", x = "Day Type", y = "Mean Traffic")
weather <- read_csv("~/Desktop/weather_data.csv") %>%  # Replace with your actual filename
mutate(
date = as_date(`DATE`),  # Replace `DATE` with actual column name
precipitation = as.numeric(`PRCP`),  # Replace with actual precipitation column
snow = as.numeric(`SNOW`)            # Replace with actual snow column
) %>%
select(date, precipitation, snow) %>%
drop_na()
df_traffic <- df_traffic %>%
mutate(date = as_date(datetime))
df_traffic <- weather %>%
left_join(df_traffic, by = "date")
df_traffic <- df_traffic %>%
select(datetime, date, traffic, holiday, precipitation, snow)
# Effect of precipitation on traffic
ggplot(df_traffic, aes(x = precipitation, y = traffic)) +
geom_point(alpha = 0.2) +
geom_smooth(method = "loess", color = "blue") +
labs(title = "Traffic vs Precipitation", x = "Precipitation (inches)", y = "Traffic")
# Effect of snow on traffic
ggplot(df_traffic, aes(x = snow, y = traffic)) +
geom_point(alpha = 0.2) +
geom_smooth(method = "loess", color = "steelblue") +
labs(title = "Traffic vs Snowfall", x = "Snowfall (inches)", y = "Traffic")
# 1. Fix duplicate datetime entries (average values per hour if needed)
df_clean <- df_traffic %>%
group_by(datetime) %>%
summarise(across(where(is.numeric), mean, na.rm = TRUE), .groups = "drop")
# 2. Convert to a tsibble and fill missing hourly timestamps
df_clean <- df_clean %>%
as_tsibble(index = datetime) %>%
fill_gaps()
# 3. Identify and replace full "zero-traffic" days with NA
zero_days <- df_clean %>%
mutate(date = as_date(datetime)) %>%
group_by(date) %>%
summarise(daily_total = sum(traffic, na.rm = TRUE), .groups = "drop") %>%
filter(daily_total == 0) %>%
pull(date)
df_clean <- df_clean %>%
mutate(date = as_date(datetime)) %>%
mutate(traffic = if_else(date %in% zero_days, NA_real_, traffic)) %>%
select(-date)
# 4. Interpolate missing values
df_clean <- df_clean %>%
mutate(traffic = na.approx(traffic, na.rm = FALSE))
# 5. Detect outliers with STL decomposition
decomposition <- df_clean %>%
model(STL(traffic ~ season(window = "periodic"), robust = TRUE)) %>%
fabletools::components()
iqr <- IQR(decomposition$remainder, na.rm = TRUE)
outliers <- decomposition %>%
filter(remainder > quantile(remainder, 0.75, na.rm = TRUE) + 3 * iqr |
remainder < quantile(remainder, 0.25, na.rm = TRUE) - 3 * iqr)
decomposition %>% autoplot() +
labs(title = "STL Decomposition of Cleaned Traffic Data") +
theme_minimal()
# We'll use the last 744 hours of 2016 (i.e. January 1st 00:00 is excluded) as test set
train_data <- df_clean %>% filter(datetime < ymd_h("2016-12-01 00"))
test_data <- df_clean %>% filter(datetime >= ymd_h("2016-12-01 00"))
# Fit models on training data (for validation only)
fit_ets_train <- train_data %>%
model(ETS(traffic ~ error("A") + trend("N") + season("N")))
fit_arima_train <- train_data %>%
model(ARIMA(traffic))
fit_arima_xreg_train <- train_data %>%
model(ARIMA(traffic ~ holiday + precipitation + snow))
fit_arima_xreg_train_h <- train_data %>%
model(ARIMA(traffic ~ holiday))
fit_arima_xreg_train_p <- train_data %>%
model(ARIMA(traffic ~ precipitation))
fit_arima_xreg_train_s <- train_data %>%
model(ARIMA(traffic ~ snow))
fit_arima_xreg_train_hp <- train_data %>%
model(ARIMA(traffic ~ holiday + precipitation))
fit_arima_xreg_train_ps <- train_data %>%
model(ARIMA(traffic ~ precipitation + snow))
fit_arima_xreg_train_hs <- train_data %>%
model(ARIMA(traffic ~ holiday + snow))
