---
title: "Forecasting Traffic at Sensor 198"
author: "Ana Blanco Lara, Imen Rabouhi Announ, Xavier Dubrul & Camille Toan"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(tsibble)
library(lubridate)
library(fable)
library(feasts)
library(readr)
library(scales)
```

# Step 1: Exploration and Visualization

We started by loading the data.

```{r}
# Load the data
df <- read_csv("traffic_data.csv")
df <- df[-1, ]  # Remove first row with sensor URLs
```

## Sensor 198

We then converted it to the proper format, by only choosing to keep the data from our own Sensor (number 198).

```{r}
# Convert to proper format
df <- df %>%
  mutate(
    datetime = dmy_hm(Time),
    traffic = as.numeric(Sensor198)
    ) %>%
  select(datetime, traffic) %>%
  as_tsibble(index = datetime)
```

## Time series

## We can now see the full time series.

```{r}
# Full time series
df %>% autoplot(traffic)

ggplot(df, aes(x = datetime, y = traffic)) +
  geom_line(color = "black") +
  labs(
    title = "Traffic at Sensor 198",
    x = "Time",
    y = "Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

We can see that there is a lot of data and many many values, making this graph very hard to read or find clear trends.

Therefore, we decided to explore a few of the initial visualizations to try to find some patterns.

## Traffic distribution

To get a better overview of the distribution of the traffic we have also included a simple graph showing the most frequent normalized traffic volume. As a result we can see that the most common is 0.05.

```{r}
# Traffic distribution 
ggplot(df, aes(x = traffic)) +
  geom_histogram(binwidth = 0.05, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Traffic Values", x = "Traffic", y = "Count") +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

## Holidays 

```{r}

# Parse the timestamp column (adjust the name if different)
df$datetime <- ymd_hms(df$datetime)

# Extract the date component
df$date <- as_date(df$datetime)

# Define the list of holidays in 2015 and 2016
holidays <- as_date(c(as.POSIXct(
  "2015-01-01", "2015-01-19", "2015-02-16", "2015-03-31", "2015-05-25",
  "2015-07-04", "2015-09-07", "2015-10-12", "2015-11-11", "2015-11-26",
  "2015-11-27", "2015-12-25", "2016-01-01", "2016-01-18", "2016-02-15",
  "2016-03-31", "2016-05-30", "2016-07-04", "2016-09-05", "2016-10-10",
  "2016-11-11", "2016-11-24", "2016-11-25", "2016-12-25"
)))

# Add the holiday indicator
df <- df %>%
  mutate(holiday = if_else(datetime %in% holidays, 1L, 0L))

# Compute mean traffic grouped by holiday
mean_traffic_by_holiday <- df %>%
  group_by(holiday) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE)) %>%
  mutate(holiday = factor(holiday, levels = c(0, 1), labels = c("Non-Holiday", "Holiday")))

# Plot
ggplot(mean_traffic_by_holiday, aes(x = holiday, y = mean_traffic)) +
  geom_col(width = 0.8, fill = "lightblue") +
  labs(
    title = "Mean Traffic by Holiday Status",
    x = "Day Type",
    y = "Mean Traffic"
  ) +
  theme_minimal()
```

## Monthly seasonality

First, we wanted to see if there were any trends or seasonalities visible when looking at the data of an entire year, separating it by months.

We can now see the data for all of the year 2015.

We have also included the data for all of the year 2016.

```{r}
# Monthly seasonality
df %>% gg_season(traffic, period = "month")


# Ensure datetime is in correct format
df <- df %>%
  mutate(datetime = as.POSIXct(datetime))

# Aggregate monthly mean traffic for 2015
df_monthly <- df %>%
  filter(year(datetime) == 2015) %>%
  mutate(month = floor_date(datetime, unit = "month")) %>%
  group_by(month) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE)) %>%
  ungroup()

# Plot monthly mean traffic for 2015 
ggplot(df_monthly, aes(x = month, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  geom_point(size = 2) +
  labs(
    title = "Monthly Mean Traffic – 2015",
    x = "Month",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# Aggregate monthly mean traffic for 2016
df_monthly <- df %>%
  filter(year(datetime) == 2016) %>%
  mutate(month = floor_date(datetime, unit = "month")) %>%
  group_by(month) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE)) %>%
  ungroup()

# Plot monthly mean traffic for 2016
ggplot(df_monthly, aes(x = month, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  geom_point(size = 2) +
  labs(
    title = "Monthly Mean Traffic – 2016",
    x = "Month",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text.x = element_text(angle = 45, hjust = 1)
  )
```

These first graphs already show some potential changes, specifically the large increase in traffic in the year 2016 compared to 2015. This could be due to many factors including economic growth, population growth or even an increase in tourist.

## Weekly seasonality

Then, we explored the potential of a visible trend or seasonality when looking at the data of an entire month, separating it by days and marking the start of each new week (the months always start on Mondays).

To have the best estimation possible, we have chosen five months at random over the course of the two years.

```{r}
# Weekly seasonality
df %>% gg_season(traffic, period = "week")


#June 2015
#Aggregate traffic per day
df_daily <- df %>%
  filter(datetime >= as.POSIXct("2015-06-01") & datetime < as.POSIXct("2015-06-29")) %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE))

#Plot daily mean
ggplot(df_daily, aes(x = date, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  labs(
    title = "Daily Mean Traffic – June 2015 starting on a Monday",
    x = "Date",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(size = 7)
  )

#August 2015
#Aggregate traffic per day
df_daily <- df %>%
  filter(datetime >= as.POSIXct("2015-08-03") & datetime < as.POSIXct("2015-08-31")) %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE))

#Plot daily mean
ggplot(df_daily, aes(x = date, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  labs(
    title = "Daily Mean Traffic – August 2015 starting on a Monday",
    x = "Date",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(size = 7)
  )


#September 2015
#Aggregate traffic per day
df_daily <- df %>%
  filter(datetime >= as.POSIXct("2015-08-31") & datetime < as.POSIXct("2015-09-28")) %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE))

#Plot daily mean
ggplot(df_daily, aes(x = date, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  labs(
    title = "Daily Mean Traffic – September 2015 starting on a Monday",
    x = "Date",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(size = 7)
  )


#October 2015
#Aggregate traffic per day
df_daily <- df %>%
  filter(datetime >= as.POSIXct("2015-10-05") & datetime < as.POSIXct("2015-11-02")) %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE))

#Plot daily mean
ggplot(df_daily, aes(x = date, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  labs(
    title = "Daily Mean Traffic – October 2015 starting on a Monday",
    x = "Date",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(size = 7)
  )

#March 2016 
#Aggregate traffic per day
df_daily <- df %>%
  filter(datetime >= as.POSIXct("2016-03-07") & datetime < as.POSIXct("2016-04-04")) %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE))

#Plot daily mean
ggplot(df_daily, aes(x = date, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  labs(
    title = "Daily Mean Traffic – March 2016 starting on a Monday",
    x = "Date",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(size = 7)
  )


#August 2016
#Aggregate traffic per day
df_daily <- df %>%
  filter(datetime >= as.POSIXct("2016-08-01") & datetime < as.POSIXct("2016-08-29")) %>%
  mutate(date = as.Date(datetime)) %>%
  group_by(date) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE))

#Plot daily mean
ggplot(df_daily, aes(x = date, y = mean_traffic)) +
  geom_line(color = "steelblue") +
  labs(
    title = "Daily Mean Traffic – August 2016 starting on a Monday",
    x = "Date",
    y = "Mean Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    axis.text = element_text(size = 7)
  )
```

We can already see a clear seasonal weekly trend, the week-ends are almost always marked with a clear decrease in traffic, most likely due to the lack of need for commuting.

We can also see that months that are very popular to be holidays, show less signs of this trend.

Let's now see if we can see this "commute trend" on the daily seasonality results.

## Daily seasonality

```{r}
# Daily seasonality 
# Filter for a random week in the middle of September 2015 and extract weekday + hour
df_week <- df %>%
  filter(datetime >= as.POSIXct("2015-09-15") & datetime < as.POSIXct("2015-09-22")) %>%
  mutate(
    weekday = factor(weekdays(datetime),
        levels = c("Monday", "Tuesday", "Wednesday", "Thursday",
                                "Friday", "Saturday", "Sunday")),
    weekday_num = as.numeric(weekday),  
    offset_traffic = traffic + (7 - weekday_num) * 0.15,
    hour = hour(datetime)
  )

# Plot: hourly traffic per day (faceted by weekday)
ggplot(df_week, aes(x = hour, y = traffic)) +
  geom_line() +
  facet_wrap(~ weekday, ncol = 3) +
  labs(
    title = "Hourly Traffic by Day – Week in the middle of September 2015",
    x = "Hour of Day", y = "Traffic"
  ) +
  theme_minimal()+
  theme(
    plot.title = element_text(hjust = 0.5), 
    strip.text = element_text(size = 8),
    axis.text.x = element_text(size = 8)
)

# Step 1: Add weekday and hour columns
df_summary <- df %>%
  mutate(
    weekday = factor(weekdays(datetime),
                     levels = c("Monday", "Tuesday", "Wednesday", "Thursday",
                                "Friday", "Saturday", "Sunday")),
    hour = hour(datetime)
  ) %>%
  group_by(weekday, hour) %>%
  summarise(mean_traffic = mean(traffic, na.rm = TRUE)) %>%
  ungroup()

# Step 2: Plot the average traffic
ggplot(df_summary, aes(x = hour, y = mean_traffic)) +
  geom_line() +
  facet_wrap(~ weekday, ncol = 3) +
  labs(
    title = "Average Hourly Traffic by Day of the Week",
    x = "Hour of Day",
    y = "Average Traffic"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    strip.text = element_text(size = 8),
    axis.text.x = element_text(size = 8)
  )
```

The traffic tends to be more dense on commuting hours on weekdays, which we expected from the start, showing the higher volume of traffic due to people going to and from their office in the morning and evening (around 8am and 4pm). This is a trend we could already predict given the data was all gathered from before the COVID-19 pandemic and people would rarely choose or even be given the option of work from home. On weekends we see much less traffic, especially on Sunday. Furthermore, the traffic on week-ends is much more constant.

## Autocorrelation function (ACF)

```{r}
# ACF
df %>% ACF(traffic) %>% autoplot()
```

Finally, the autocorrelation function (ACF) plot confirms these patterns, it shows strong autocorrelation at lags corresponding to 24 hours (daily). This means that the series is highly seasonal and autocorrelated, which is why we have decided to apply a SARIMA model.

```{r}
zero_traffic <- df %>% filter(traffic == 0)
print(zero_traffic)
```

# Step 2: Cleaning and Wrangling

```{r}
library(ggplot2)

# 1. Start from original df
df_clean <- df

# 2. Fill missing hourly timestamps
df_clean <- df_clean %>% fill_gaps()

# 3. Identify full-zero days (likely sensor failure)
zero_days <- df_clean %>%
  mutate(date = as_date(datetime)) %>%
  group_by(date) %>%
  summarise(daily_sum = sum(traffic, na.rm = TRUE)) %>%
  filter(daily_sum == 0) %>%
  pull(date)

# 4. Replace all values on those days with NA
df_clean <- df_clean %>%
  mutate(date = as_date(datetime)) %>%
  mutate(traffic = if_else(date %in% zero_days, NA_real_, traffic)) %>%
  select(-date)

# 5. Interpolate missing values linearly
df_clean <- df_clean %>%
  mutate(traffic = zoo::na.approx(traffic, na.rm = FALSE))  # requires library(zoo)

# 6. STL decomposition to identify outliers
decomp <- df_clean %>%
  model(STL(traffic ~ season(window = "periodic"), robust = TRUE)) %>%
  components()

iqr <- IQR(decomp$remainder, na.rm = TRUE)

outliers <- decomp %>%
  filter(remainder > quantile(remainder, 0.75, na.rm = TRUE) + 3 * iqr |
         remainder < quantile(remainder, 0.25, na.rm = TRUE) - 3 * iqr)

# Visualize outliers or decide whether to smooth them
decomp %>% autoplot() +
  labs(title = "STL Decomposition of Cleaned Traffic Data") +
  theme_minimal()

# Join STL components (as tibble) with traffic data
decomp_joined <- df_clean %>%
  left_join(decomp %>% as_tibble(), by = "datetime") %>%
  rename(traffic = traffic.x)  # Rename to avoid .x in ggplot

# Plot traffic with STL outliers in red
ggplot(decomp_joined, aes(x = datetime, y = traffic)) +
  geom_line(color = "steelblue") +
  geom_point(data = filter(decomp_joined, datetime %in% outliers$datetime),
             mapping = aes(x = datetime, y = traffic), color = "red", size = 1.5) +
  labs(title = "Traffic with Outliers (from STL Remainder)",
       x = "Time", y = "Traffic Volume") +
  theme_minimal()
# df_clean is now cleaned and ready for modeling
```

To better understand and clean the time series, we apply STL decomposition with three seasonal components: annual, weekly, and daily. We use a robust estimation procedure to reduce the influence of extreme outliers. The decomposition reveals a steadily increasing trend over the two-year period, suggesting that overall traffic at Sensor 198 slightly increased over time. The weekly and daily seasonal components are both strong and stable, with the weekly pattern confirming lower traffic on weekends, and the daily pattern showing the expected rise during commuting hours. The remainder component still contains some variability, indicating occasional irregular fluctuations or localized anomalies that may not follow a consistent seasonal or trend pattern. This decomposition validates our earlier visual observations and confirms the presence of both weekly and daily seasonality, justifying the use of seasonal models in the next step.

# Step 3: Modeling

```{r}
# Exponential Smoothing
fit_ets <- df %>% model(ETS(traffic))

# ARIMA
fit_arima <- df %>% model(ARIMA(traffic))

# Time Series Linear Model
fit_tslm <- df %>% model(TSLM(traffic ~ trend() + season("day")))

# Summaries
report(fit_ets)
report(fit_arima)
report(fit_tslm)
```

# Step 4: Forecast and Validation

```{r}
# Split data: training set up to Dec 31, 2016
df_train <- df %>% filter(datetime < ymd("2017-01-01"))

# Fit models on training set
fit_arima <- df_train %>% model(ARIMA(traffic))
fit_ets   <- df_train %>% model(ETS(traffic))
fit_tslm  <- df_train %>% model(TSLM(traffic ~ trend() + season("day")))

# Forecast 744 hours (Jan 2017) with 95% intervals
fc_arima <- fit_arima %>% forecast(h = "744 hours", level = 95)
fc_ets   <- fit_ets   %>% forecast(h = "744 hours", level = 95)
fc_tslm  <- fit_tslm  %>% forecast(h = "744 hours", level = 95)

# Plot ARIMA forecast
fc_arima %>% autoplot(df) + labs(title = "ARIMA Forecast for January 2017")

# Convert to required format
fc_arima_unpacked <- fc_arima %>%
  hilo() %>%
  unpack_hilo(`95%`)

final_fc <- fc_arima_unpacked %>%
  as_tibble() %>%
  transmute(
    datetime = as.character(datetime),
    forecast = .mean,
    upper_97.5 = `95%_upper`,
    lower_2.5 = `95%_lower`
  )

# Save to CSV
write_csv(final_fc, "sensor198_forecast.csv")
```
